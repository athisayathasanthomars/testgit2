# -*- coding: utf-8 -*-
"""Breast_Cancer_Prediction-AF/20/16913

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10fd5u9gJXgfNu7itACkgfSUqa6HrzVlp

**AF-20-16850**

**Oveya Jeyaraj**
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir("/content/drive/MyDrive/Assignment_ML/classification")

import pandas as pd

breast_cancer = pd.read_csv("/content/drive/MyDrive/Assignment_ML/classification/breast-cancer.csv")
# Remove unwanted variables (if any)
# In this case, 'id' is not necessary for the classification task
breast_cancer = breast_cancer.drop('id', axis=1)
#printing sample row data
breast_cancer.head()

"""ID is not used to predict. its unwanted. so we're dropping it."""

breast_cancer.info()

from sklearn.preprocessing import LabelEncoder, StandardScaler
# Convert 'diagnosis' column to numerical values using label encoding

label_encoder = LabelEncoder()
breast_cancer['diagnosis'] = label_encoder.fit_transform(breast_cancer['diagnosis'])

import seaborn as sns
import matplotlib.pyplot as plt

import matplotlib.pyplot as plt

#defined features and breast_cancer

fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))
axs = axs.flatten()

for index, feature in enumerate(features):
    if index < len(axs):  # Check if the index is within the bounds of the axs array
        sns.boxplot(data=breast_cancer, x=feature, hue='diagnosis', ax=axs[index])
    else:
        break  # Break out of the loop if the index exceeds the size of axs

# Set the 6th subplot as invisible if necessary
if len(features) < len(axs):
    axs[-1].set_visible(False)

plt.tight_layout()
plt.show()

corr_matrix = breast_cancer.corr()

fig, ax = plt.subplots(figsize=(20,10))
sns.heatmap(corr_matrix, annot=True, cmap = 'coolwarm', ax=ax)
plt.show()

"""## **Model Development**

# **Spliting data and data process**
"""

from sklearn.model_selection import train_test_split

"""Removing the dependent variable and one of the highly correlated independent variable- radius is the one of the highly corelated variable identified through heatmap."""

features_updated = breast_cancer.columns.drop(['diagnosis', 'concave points_worst']).tolist()

print(features_updated)

X = breast_cancer[features_updated]
y = breast_cancer['diagnosis']

y.value_counts(normalize=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)

y_test.value_counts(normalize=True)

"""# **1. Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Scaling the input features can help the optimization algorithm converge faster."""

log_reg = LogisticRegression()

log_reg.fit(X_train_scaled, y_train)
y_pred_log_reg = log_reg.predict(X_test)

y_pred_log_reg

log_reg.coef_

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

"""We can calculate precision, recall, F1-score, and accuracy score using scikit-learn's precision_score, recall_score, f1_score, and accuracy_score functions."""

precision = precision_score(y_test, y_pred_log_reg, average='weighted')
recall = recall_score(y_test, y_pred_log_reg, average='weighted')
f1 = f1_score(y_test, y_pred_log_reg, average='weighted')
accuracy = accuracy_score(y_test, y_pred_log_reg)

"""The average='weighted' parameter calculates metrics for each label and finds their average weighted by support, which is the number of true instances for each label. This is useful for multiclass problems."""

print("Precision: {:.2f}".format(precision))
print("Recall: {:.2f}".format(recall))
print("F1-score: {:.2f}".format(f1))
print("Accuracy: {:.2f}".format(accuracy))

from yellowbrick.classifier import confusion_matrix
from yellowbrick.classifier import classification_report
from yellowbrick.classifier import roc_auc
from yellowbrick.classifier import class_prediction_error
from yellowbrick.classifier import discrimination_threshold
from yellowbrick.classifier import precision_recall_curve

conf_matrix_log_reg_base = confusion_matrix(log_reg, X_test, y_test, cmap="Greens")

class_prediction_error(log_reg, X_test, y_test)

class_report_log_reg_base = classification_report(log_reg, X_test, y_test)

roc_log_reg_base = roc_auc(log_reg, X_test_scaled, y_test, binary=True)

prec_recall_log_reg = precision_recall_curve(log_reg, X_test, y_test)

disc_thresh_log_reg = discrimination_threshold(log_reg, X_test_scaled, y_test)

"""# **2. support vector machines**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from yellowbrick.classifier import ConfusionMatrix, ClassPredictionError, ClassificationReport, ROCAUC, PrecisionRecallCurve, DiscriminationThreshold

X_train.head()

svm = SVC()
svm.fit(X_train_scaled, y_train)
y_pred_svm = svm.predict(X_test_scaled)

# Calculate precision, recall, f1-score, and accuracy score
precision = precision_score(y_test, y_pred_svm, average='weighted')
recall = recall_score(y_test, y_pred_svm, average='weighted')
f1 = f1_score(y_test, y_pred_svm, average='weighted')
accuracy = accuracy_score(y_test, y_pred_svm)

print("Precision: {:.2f}".format(precision))
print("Recall: {:.2f}".format(recall))
print("F1-score: {:.2f}".format(f1))
print("Accuracy: {:.2f}".format(accuracy))

# Create a confusion matrix
conf_matrix_svm = ConfusionMatrix(svm, classes=svm.classes_, cmap="Greens")
conf_matrix_svm.fit(X_train_scaled, y_train)
conf_matrix_svm.score(X_test_scaled, y_test)
conf_matrix_svm.show()

# Create a class prediction error plot
class_error_svm = ClassPredictionError(svm, classes=svm.classes_)
class_error_svm.score(X_test_scaled, y_test)
class_error_svm.show()

# Create a classification report
class_report_svm = ClassificationReport(svm, classes=svm.classes_, support=True, cmap="Greens")
class_report_svm.fit(X_train_scaled, y_train)
class_report_svm.score(X_test_scaled, y_test)
class_report_svm.show()

# Create an ROC curve
roc_svm = ROCAUC(svm, classes=svm.classes_, binary=True)
roc_svm.fit(X_train_scaled, y_train)
roc_svm.score(X_test_scaled, y_test)
roc_svm.show()

# Create a precision-recall curve
prec_recall_svm = PrecisionRecallCurve(svm, classes=svm.classes_)
prec_recall_svm.fit(X_train_scaled, y_train)
prec_recall_svm.score(X_test_scaled, y_test)
prec_recall_svm.show()

# Create a discrimination threshold plot
disc_thresh_svm = DiscriminationThreshold(svm)
disc_thresh_svm.fit(X_train_scaled, y_train)
disc_thresh_svm.score(X_test_scaled, y_test)
disc_thresh_svm.show()

"""# **3. Decision Trees**"""

from sklearn.tree import DecisionTreeClassifier
from yellowbrick.classifier import ConfusionMatrix, ClassPredictionError, ClassificationReport, ROCAUC, PrecisionRecallCurve, DiscriminationThreshold

clf_dt = DecisionTreeClassifier(random_state=55)

clf_dt.fit(X_train, y_train)

y_pred_dt = clf_dt.predict(X_test)

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

precision = precision_score(y_test, y_pred_dt, average='weighted')
recall = recall_score(y_test,y_pred_dt, average='weighted')
f1 = f1_score(y_test,y_pred_dt, average='weighted')
accuracy = accuracy_score(y_test,y_pred_dt)

print("Precision: {:.2f}".format(precision))
print("Recall: {:.2f}".format(recall))
print("F1-score: {:.2f}".format(f1))
print("Accuracy: {:.2f}".format(accuracy))

# Create a confusion matrix
conf_matrix_dt = ConfusionMatrix(clf_dt, classes=clf_dt.classes_, cmap="Greens")
conf_matrix_dt.fit(X_train, y_train)
conf_matrix_dt.score(X_test, y_test)
conf_matrix_dt.show()

# Create a class prediction error plot
class_error_dt = ClassPredictionError(clf_dt, classes=clf_dt.classes_)
class_error_dt.score(X_test, y_test)
class_error_dt.show()

# Create a classification report
class_report_dt = ClassificationReport(clf_dt, classes=clf_dt.classes_, support=True, cmap="Greens")
class_report_dt.fit(X_train, y_train)
class_report_dt.score(X_test, y_test)
class_report_dt.show()

# Create an ROC curve (set binary=True for multiclass)
roc_dt = ROCAUC(clf_dt, classes=clf_dt.classes_, binary=True)
roc_dt.fit(X_train, y_train)
roc_dt.score(X_test, y_test)
roc_dt.show()

# Create a precision-recall curve
prec_recall_dt = PrecisionRecallCurve(clf_dt, classes=clf_dt.classes_)
prec_recall_dt.fit(X_train, y_train)
prec_recall_dt.score(X_test, y_test)
prec_recall_dt.show()

# Create a discrimination threshold plot
disc_thresh_dt = DiscriminationThreshold(clf_dt)
disc_thresh_dt.fit(X_train, y_train)
disc_thresh_dt.score(X_test, y_test)
disc_thresh_dt.show()

"""## **Suitable Algorithm**

**Logistic Regression:**
- Precision: 0.14
- Recall: 0.37
- F1-score: 0.20
- Accuracy: 0.37

**Support Vector Machines (SVM):**
- Precision: 0.97
- Recall: 0.96
- F1-score: 0.97
- Accuracy: 0.96

**Classification Decision Tree:**
- Precision: 0.93
- Recall: 0.92
- F1-score: 0.92
- Accuracy: 0.92

Support Vector Machines (SVM) perform better in terms of precision, recall, F1-score, and accuracy than Logistic Regression and Classification Decision Trees, according to the criteria given. SVM performs better overall, achieving the highest values across all evaluation metrics.

Therefore, Support Vector Machines (SVM) would be the best algorithm for your dataset if you emphasize accuracy and overall performance. But depending on your unique needs and limitations, it's crucial to take additional aspects like computational complexity, interpretability, and scalability into account.

## **Challenges and Solutions**

One challenge in creating visualization plots for classification algorithms like Support Vector Machines (SVM) or Decision Trees is dealing with high-dimensional feature spaces.Working with high-dimensional feature spaces presents a problem when designing visualization plots for classification methods such as Support Vector Machines (SVM) or Decision Trees.


To solve this, frequently use methods like dimensionality reduction, sophisticated plotting libraries (like Matplotlib, Seaborn, or Plotly), and interactive visualization tools to successfully examine and interpret categorization results in order to get around these difficulties.
"""